{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia - this day in history <small>(step 2)</small>\n",
    "---\n",
    "**Goal:** create a dataset of this-day-in-history events  \n",
    "  \n",
    "**Context:**  I need a starting dataset of world history events (name, short description, long description, image, and location). I couldn't find public datasets. I'm building one using the wikipedia this day in history data.\n",
    "\n",
    "**Notes about this notebook:**  \n",
    "- this notebook is for the second step of this project. \n",
    "- the notebook for the first step is [TADS_wikipedia_tdih_main_api_step_01_02_get_data_29jan21](http://localhost:8888/notebooks/temp_for_offline/bianca_aguglia/projects_wip/TADS_wikipedia_this_day_in_history/TADS_wikipedia_tdih_main_api_step_01_02_get_data_29jan21.ipynb)\n",
    "- the first step consisted of:\n",
    "    - using the Wikipedia api to get the events for each day of the year\n",
    "    - parsing the Wikipedia data, cleaning it up, and getting it in the right format needed for the SQLite database created for this project\n",
    "- step two is:\n",
    "    - take the data from step one and rank each item based on page views, page length, and links to page\n",
    "    - get image (and licence details) for each item in the data from step one\n",
    "- to get data for a specific day run day_data_main(day_name). It returns a dictionary with day data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process flow: <small>(with checkmarks for steps done in this notebook)</small>\n",
    "- get day data\n",
    "    - save data in wikipedia_tdih.db\n",
    "- get link data\n",
    "    - [ ] query wikipedia_tdih.db for:\n",
    "        - [x] links that are new (i.e. in wiki_link but not in wiki_get_link_data_log)\n",
    "        - [x] links that have have not been updated since a specified_date\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import config\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_FILE = 'wikipedia_tdih.db'\n",
    "HEADERS = config.HEADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_data_main(database_file = DATABASE_FILE, date = ''):\n",
    "    \"\"\"\n",
    "    Get link data for a group of links in wikipedia_tdih.db.\n",
    "    \n",
    "    Params:\n",
    "        database_file:\n",
    "        date: \n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(DATABASE_FILE) as connection:\n",
    "        c = connection.cursor()\n",
    "        \n",
    "    links_list = get_links_to_update_from_db(c, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_to_update_from_db(database_cursor, date = ''):\n",
    "    \"\"\"\n",
    "    Select from wikipedia_tdih.db the links for which wikipedia data is needed.\n",
    "    \n",
    "    There are two cases in which data is needed for a specific link:\n",
    "        1. the link has just been added to the wikipedia_tdih.db and link data has not been requested from \n",
    "           wikipedia API yet\n",
    "        2. the existing data for the link needs to be updated\n",
    "    \n",
    "    Params:\n",
    "        date: default of '' indicates that only links without data should be selected\n",
    "              if date is given, select the links that have data but data has not been updated since specified date\n",
    "              if date is given, format should be '%Y-%m-%d' (e.g. '2021-01-02' for January 2nd, 2021)\n",
    "              \n",
    "    Returns:\n",
    "        links_list: list of links for which wikpedia data is needed\n",
    "    \"\"\"\n",
    "    \n",
    "    c = database_cursor\n",
    "    \n",
    "    # if no date is given\n",
    "    if not date:\n",
    "        # select the links that are in wiki_link but not in wiki_get_link_data_log\n",
    "        # (these are links which have just been added to wiki_link)\n",
    "        links_list = c.execute('''SELECT link_id, link_url FROM wiki_link WHERE link_id NOT IN (\n",
    "                                    SELECT link_id FROM wiki_get_link_data_log) ''').fetchall()\n",
    "    \n",
    "    # if date is given\n",
    "    else:\n",
    "        links_list = c.execute('''SELECT link_id, link_url FROM wiki_link WHERE link_id IN (\n",
    "                                    SELECT link_id FROM wiki_get_link_data_log WHERE doe > ?)''', (date,)).fetchall()\n",
    "      \n",
    "    return links_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
